{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Complete_09242020_Biomarker_Lecture_02.ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnY-HGloLRO4",
        "colab_type": "text"
      },
      "source": [
        "# Microarray File Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kecS3SvRBQA",
        "colab_type": "text"
      },
      "source": [
        "## Imports\n",
        "- ftplib\n",
        "  - File Transfer Protocol Library\n",
        "  - Used for downloading files from FTP servers\n",
        "- gzip\n",
        "  - Package used for uncompressing gzipped files\n",
        "- os\n",
        "  - Os is a library for working with the file system|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G07l9EaKJyoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ftplib import FTP\n",
        "import gzip\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrrTtEtONf9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = pd.read_csv(\n",
        "    'http://pubs.broadinstitute.org/mpr/projects/Leukemia/data_set_ALL_AML_train.txt',\n",
        "    sep='\\t'\n",
        "    )\n",
        "\n",
        "cols = d.columns\n",
        "d = d.reset_index().drop(columns='call.37')\n",
        "d.columns = cols\n",
        "d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdju8c2nRm-x",
        "colab_type": "text"
      },
      "source": [
        "## Downloading the Data\n",
        "\n",
        "I found this dataset using NCBI's GEO data portal (https://www.ncbi.nlm.nih.gov/geo/)\n",
        "\n",
        "Gene expression profile of human colorectal carcinoma (https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE113513)\n",
        "\n",
        "The URL needs to be split into three parts to work with the FTP package\n",
        "- HOST_NAME\n",
        "  - The address for NCBI's ftp server\n",
        "- HOST_DATA_PATH\n",
        "  - The path to the studies file on the FTP server\n",
        "- HOST_FILE_NAME\n",
        "  - This is the microarray output file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBn9goauRfOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HOST_NAME = 'ftp.ncbi.nlm.nih.gov'\n",
        "HOST_DATA_PATH = 'geo/series/GSE113nnn/GSE113513/matrix/'\n",
        "HOST_FILE_NAME = 'GSE113513_series_matrix.txt.gz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsI7vWnpXDDy",
        "colab_type": "text"
      },
      "source": [
        "We can now use the paths we just defined to download the file from the ftp server\n",
        "\n",
        "Some notes:\n",
        "- The file is compressed using gzip (.gz) so we will need to use the gzip package to uncompress it to view its contents\n",
        "- Pandas is able to read .gz files\n",
        "\n",
        "The downloaded file is saved in the current runtime. When you start a new session you will need to download the file again. You can link your Google Drive to the notebook to save the file there permanently if required.\n",
        "\n",
        "The lines that start with '!' are part of the header, we will use this to tell pandas to ignore these lines when loading the dataframe.\n",
        "\n",
        "We will need to load this data separately though, as it specifies the sample types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOra1c1sW-Ig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Same as above\n",
        "ftp = FTP(HOST_NAME)\n",
        "ftp.login()\n",
        "ftp.cwd(HOST_DATA_PATH)\n",
        "\n",
        "RAW_DATA_DIR = './data/raw/'\n",
        "\n",
        "# if the ./data/raw/ path does not exist, create it\n",
        "if not os.path.exists(RAW_DATA_DIR):\n",
        "    os.makedirs(RAW_DATA_DIR)\n",
        "\n",
        "# Download the file as a binary file\n",
        "# RETR <file_name> : means retrieve that file\n",
        "# open(...) opens a binary file to write the data to\n",
        "ftp.retrbinary(\n",
        "    'RETR {}'.format(HOST_FILE_NAME) , \n",
        "    open('{}{}'.format(RAW_DATA_DIR, HOST_FILE_NAME), 'wb').write\n",
        ")\n",
        "\n",
        "# This looks at the first 75 lines in the file to evaluate the file format\n",
        "\n",
        "with gzip.open('{}{}'.format(RAW_DATA_DIR, HOST_FILE_NAME)) as fh:\n",
        "    for i, line in enumerate(fh.readlines()):\n",
        "        print(line)\n",
        "        if i == 75:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlqL2V5sLj5I",
        "colab_type": "text"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv_pFggFYNm7",
        "colab_type": "text"
      },
      "source": [
        "## Imports\n",
        "- gzip\n",
        "  - We need to read the gzipped file to extract the meta data\n",
        "- matplotlib\n",
        "  - We use matplotlib to create some plots and adjust seaborn plots\n",
        "- numpy\n",
        "  - We use some of numpys functions for transforming the data\n",
        "- pandas\n",
        "  - We use pandas to manipulate the tabular data\n",
        "- seaborn\n",
        "  - We use seaborn for statistical plots\n",
        "\n",
        "  We first import the packages we need. Then we set some global parameters used for generating plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6BjngYvLYhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gzip is a pacakge for opening/making gz files\n",
        "import gzip\n",
        "# import plt for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "# import numpy for Array creation/manipulation\n",
        "import numpy as np\n",
        "# import os for working with local files\n",
        "import os\n",
        "# pandas is a package for creating / editing data frames\n",
        "import pandas as pd\n",
        "# seaborn is a statistical plotting package\n",
        "import seaborn as sns\n",
        "\n",
        "# generate plots in the jupyter notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# set the size of the figures \n",
        "sns.set(rc={'figure.figsize':(12,6), 'figure.dpi': 150})\n",
        "# set the backgrounds of figures to white with a grid\n",
        "sns.set_style(\"whitegrid\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9yIrTzkaOY3",
        "colab_type": "text"
      },
      "source": [
        "## Reading the Data into a Pandas Dataframe\n",
        "\n",
        "In the previous section we downloaded the data file from NCBI, we can now load that file into pandas.\n",
        "\n",
        "Pandas can read compressed files so we do not first need to uncompress it. We will set the comment flag to '!' to ignore those lines in the file. This file is also tab delimited so we will need to set the sep flag to '\\t'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ-A_1TOLwgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Path to folder containing the raw data\n",
        "RAW_DATA_DIR = './data/raw/'\n",
        "# File name of the raw data\n",
        "RAW_DATA_FILENAME = 'GSE113513_series_matrix.txt.gz'\n",
        "\n",
        "# Load the data into a dataframe\n",
        "df = pd.read_csv(\n",
        "    # This creates the full path to the file\n",
        "    '{}{}'.format(RAW_DATA_DIR, RAW_DATA_FILENAME),\n",
        "    # Ignore lines that start with '!'\n",
        "    comment='!',\n",
        "    # the character used to separate values\n",
        "    sep='\\t',\n",
        "    \n",
        ")\n",
        "# Set the index column of the dataframe to the gene codes\n",
        "df = df.set_index('ID_REF')\n",
        "# output the shape of the dataframe\n",
        "print(df.shape)\n",
        "# output the first 5 lines of the dataframe\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jNmBot7cP0C",
        "colab_type": "text"
      },
      "source": [
        "## Extracting the Meta data\n",
        "\n",
        "To extract the metadata we will first load the file into a list. Each element of the list will be one line of the file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwFvSkgLL9hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "META_DATA_RAW = []\n",
        "with gzip.open('{}{}'.format(RAW_DATA_DIR, RAW_DATA_FILENAME)) as fh:\n",
        "    for line in fh.readlines():\n",
        "        # convert the line from binary to utf and remove white spaces\n",
        "        l = line.decode().strip()\n",
        "        # if the line is not empty and the first character is a '!'\n",
        "        if l and l[0] == '!':\n",
        "            META_DATA_RAW.append(l)\n",
        "\n",
        "# Output the first 5 lines\n",
        "META_DATA_RAW[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knskGlWUdd3t",
        "colab_type": "text"
      },
      "source": [
        "Now that we have a list containing all the meta data we can process it using the function defined below.\n",
        "\n",
        "This function will output a key / value pair for each line in the metadata. Those key value pairs are then converted into the META_DATA dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCpncg15L-To",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to split each string into a key and a value\n",
        "def split_string(string):\n",
        "    # remove the \"!\" and split on the first leftmost '\\t'\n",
        "    tmp = string.strip('!').split('\\t', 1)\n",
        "    # if there was a split assign key and value to the two parts\n",
        "    # else assign the value to None\n",
        "    key, value = tmp if len(tmp) > 1 else (tmp[0], None)\n",
        "    # If there is a value\n",
        "    if value:\n",
        "        # remove quotation marks and split into a list on the tab\n",
        "        # this will always create a list\n",
        "        # if there is no tab the list will have one element\n",
        "        value = value.replace('\"', '').split('\\t')\n",
        "    # return the key and value as a tuple\n",
        "    return key, value\n",
        "# map will feed each element of META_DATA into the split_string \\\n",
        "#     function and save the result\n",
        "# dict converts the map of tuples to a dictionary\n",
        "#     the first element in the tuple is the key\n",
        "# .   the second element is the value\n",
        "META_DATA = dict(map(split_string, META_DATA_RAW))\n",
        "# output the META_DATA dictionary\n",
        "print(META_DATA.keys())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjuAJJ0Ce0oU",
        "colab_type": "text"
      },
      "source": [
        "This dictionary now contains all the metadata that we will need to label our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJKNwQpxMOig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display the geo accessions using the dict\n",
        "META_DATA['Sample_geo_accession']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhXzsA-_MPSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display the sample source\n",
        "META_DATA['Sample_source_name_ch1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RodC2Jfce7hp",
        "colab_type": "text"
      },
      "source": [
        "The next step is to combine the sample source with the geo code for each sample so that we can add this information to the pandas dataframe. We can use the zip() function to join the two arrays into a set of key value pairs. The key value pairs can then be used to create a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7EWnxfdMS0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a dictionary by merging the geo accessions with the source names\n",
        "samples = dict(\n",
        "    # make a tuple containing pairs taken fom the two lists\n",
        "    # [\n",
        "    #    (MD['SGA'][0], MD['SSNC'][0]),\n",
        "    #    (MD['SGA'][1], MD['SSNC'][1]),\n",
        "    #    ...\n",
        "    zip(\n",
        "        META_DATA['Sample_geo_accession'], \n",
        "        META_DATA['Sample_source_name_ch1'])\n",
        ")\n",
        "# output the dictionary\n",
        "samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hQhNv2vhUid",
        "colab_type": "text"
      },
      "source": [
        "We now build two lists, one containing the geo accession numbers of normal samples and the other the carcinoma samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DToa4I8pMZiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This does a few things\n",
        "#   1. filter the data to include non-cancerous samples\n",
        "#        As samples is a dictionary we split it into key-value pairs using .items()\n",
        "#        .items() -> (key, value)\n",
        "#        x[1] -> values from the tuple\n",
        "#   2. the filter function will return a list of tuples\n",
        "#        for each element in that list return the first item\n",
        "#        x[0] -> key\n",
        "norm_samples = list(\n",
        "    map(lambda x: x[0], \n",
        "        filter(\n",
        "            lambda x: x[1] == 'non-cancerous colorectal tissue', \n",
        "            samples.items()\n",
        "        )\n",
        "       )\n",
        ")\n",
        "\n",
        "# The same as above except for carcinoma samples \n",
        "carc_samples = list(\n",
        "    map(lambda x: x[0], \n",
        "        filter(\n",
        "            lambda x: x[1] == 'colorectal carcinoma tissues', \n",
        "            samples.items()\n",
        "        )\n",
        "    )\n",
        ")\n",
        "# print the lists\n",
        "print('NORM: ', ','.join(norm_samples))\n",
        "print()\n",
        "print('CARC:', ','.join(carc_samples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6knkEucFhv1w",
        "colab_type": "text"
      },
      "source": [
        "### Using the Meta Data on the DataFrame\n",
        "\n",
        "Now we can use those two lists to subset our dataframe and make sure that the shapes are correct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sUyzp4nMcA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compaare the data frame shapes to make sure it is subsetting correctly\n",
        "print('full DF', df.shape)\n",
        "# the normal samples columns\n",
        "print('norm DF', df[norm_samples].shape)\n",
        "# the carcinoma sample columns\n",
        "print('carc DF', df[carc_samples].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_95M2qlh9X6",
        "colab_type": "text"
      },
      "source": [
        "Make sure that there are no overlaps between the two classifications.\n",
        "If there were overlaps this could indicate a mistake in our meta data extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2fUb5PaMeIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make sure that there are no overlaps between sample classes\n",
        "set(norm_samples).intersection(set(carc_samples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1GohXYSiWal",
        "colab_type": "text"
      },
      "source": [
        "Check for missing values in the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-ujRKBDMhcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make sure that there are no NA values\n",
        "print('NA values in DF:', df.isna().sum().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wahhRpzE_HvD",
        "colab_type": "text"
      },
      "source": [
        "There are no missing values, so we can continue with our analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK5Ul59tiqCX",
        "colab_type": "text"
      },
      "source": [
        "## Data Validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeyK1DUakNNG",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Create a boxenplot of the data to see the range of the values\n",
        "\n",
        "This plot does not work well as the outliers are orders of magnitude larger than the mean.\n",
        "\n",
        "It is interesting that there is that band between ourliers and the distributions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPJVCC13Mjks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.boxenplot(data=df, color='#507fbf')\n",
        "_ = plt.xticks(rotation=90)\n",
        "_ = plt.xlabel('Sample')\n",
        "_ = plt.ylabel('Expression')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeZq7BV6kN_V",
        "colab_type": "text"
      },
      "source": [
        "We would like to log transform the data, but we first should check whether there are any negative values or zeroes.\n",
        "\n",
        "To do this we can use the agg function to check the min and max values for each sample.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGfnCFI0jBvz",
        "colab_type": "text"
      },
      "source": [
        "Using a log transform should result in a better representation when using the boxen plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Axa7h0B5kVRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.agg(['min', 'max'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0N7UD_-_ZiS",
        "colab_type": "text"
      },
      "source": [
        "No that we know that all the values are greater than zero we can perform a log transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g40zVmFNMmJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Log transform the data\n",
        "# This will replace the data in the dataframe with the log value, so we lose the original values\n",
        "df_log = df.apply(np.log10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd_KqtPS_gjH",
        "colab_type": "text"
      },
      "source": [
        "Visualizing the log transformed data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTyc5tIzMvbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# viewing the logged data gives a better picture of the ranges of values\n",
        "sns.boxenplot(data=df_log, color='#507fbf')\n",
        "_ = plt.xticks(rotation=90)\n",
        "_ = plt.xlabel('Sample')\n",
        "_ = plt.ylabel('Expression (log10)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3NfLyg7lUDx",
        "colab_type": "text"
      },
      "source": [
        "For demonstration purposes I will now plot a heatmap of the data.\n",
        "\n",
        "This will be messy as there is no structure to the way the data is being plotted in terms of expression.\n",
        "\n",
        "We use the logged data so that the range of values is closer together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVvHKE2dM0HR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotting a heatmap off all the expression values for all the samples\n",
        "_ = sns.heatmap(data=df_log, yticklabels=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOC0fTh8lf7p",
        "colab_type": "text"
      },
      "source": [
        "## Ranking the Genes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugL0WK46lv3F",
        "colab_type": "text"
      },
      "source": [
        "Both the ranking method used in the paper, and welch's t-test require the mean and standard deviation for each class across each gene (row).\n",
        "\n",
        "We can use the agg method to generate a new dataframe containing these metrics for normal and cacinoma samples. These dataframes can then be added onto the original dataframe as new columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vf3sg6wM2lT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add two new columns containing the mean and std for each row respectively\n",
        "df_log[['norm_mean', 'norm_std']] = df_log[norm_samples].agg(\n",
        "    ['mean', 'std'], axis=1\n",
        ")\n",
        "# The same as above but for carcinoma samples\n",
        "df_log[['carc_mean', 'carc_std']] = df_log[carc_samples].agg(\n",
        "    ['mean', 'std'], axis=1\n",
        ")\n",
        "df_log.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtTKcMDXnKS0",
        "colab_type": "text"
      },
      "source": [
        "Now that we have all the required variables we can add a new column containing the result of the t-test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiV7ebJoM26b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "# calculate welch's t test using the mean's and std's\n",
        "#            m_1 - m_2\n",
        "# t =    __________________\n",
        "#          ________________\n",
        "#         |std_1     std_2\n",
        "#         |-----  +  ----\n",
        "#       \\/ num_1     num2\n",
        "def welch_t_test(row):\n",
        "    return (\n",
        "        (row['norm_mean'] - row['carc_mean']) / \n",
        "        np.sqrt(\n",
        "            row['norm_std']/len(norm_samples) + row['carc_std']/len(carc_samples)\n",
        "        )\n",
        "    )\n",
        "# create a column called similarity containing the results of the t test\n",
        "df_log['similarity'] = df_log[['norm_mean', 'norm_std', 'carc_mean', 'carc_std']].apply(welch_t_test, axis=1)\n",
        "df_log.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf9UTgPtM510",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sort the data using the similarity\n",
        "# . once sorted we dont need any of the values used to calculate the similarity\n",
        "# . This returns a dataframe containing only expression values\n",
        "df_sorted = df_log.sort_values('similarity').drop(columns=['norm_mean', 'norm_std', 'carc_mean', 'carc_std', 'similarity'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U31oq82wqTrR",
        "colab_type": "text"
      },
      "source": [
        "We can now try plotting the heatmap again using the ranked genes.\n",
        "\n",
        "Again we do not see much overall, but when we look the the top and bottom rows we can see that there might be some separation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpUiz9JwNMkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The heatmap sorted by similarity does not show much when looking at all genes\n",
        "sns.heatmap(data=df_sorted, yticklabels=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3unI3_DqkUN",
        "colab_type": "text"
      },
      "source": [
        "## Picking the top genes\n",
        "\n",
        "We can now select the top genes for the two classes using the similarity metric we defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrtXVsiTNON8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a new dataframe containing the top 25 and bottom 25 genes by similarity\n",
        "df_features = df_sorted.head(25).append(df_sorted.tail(25))\n",
        "df_features.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wcgbBpxrDmS",
        "colab_type": "text"
      },
      "source": [
        "Visualizing this subset of the dataframe now shows nice separation when viewed as a heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATqpwHH0NQML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# when viewing this heatmap we see that the genes differentiate the data well\n",
        "sns.heatmap(data=df_features, yticklabels=False, cmap='coolwarm', square=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwAOS5vaOOll",
        "colab_type": "text"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2gGc337rkYY",
        "colab_type": "text"
      },
      "source": [
        "## Imports\n",
        "- matplotlib\n",
        "- numpy\n",
        "- pandas\n",
        "- scikit-learn\n",
        "  - Logistic Regression\n",
        "    - The model that we will fit the data to\n",
        "  - Train Test Split\n",
        "    - This function will split a dataset into a training and test set\n",
        "  - plot_confusion_matrix\n",
        "    - The function that will plot a confusion matrix using the models predictions\n",
        "  - LeaveOneOut\n",
        "    - This will implement leave one out cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-r7tXwCORCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Logistic regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.model_selection import LeaveOneOut"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iZY-aPovxif",
        "colab_type": "text"
      },
      "source": [
        "This redefines the samples classes, these are the same as what we set up earlier using the meta data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P25VwL_vOUYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dictionary of sample lables calculated earlier\n",
        "SAMPLES = {\n",
        "    'GSM3108231': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108232': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108233': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108234': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108235': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108236': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108237': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108238': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108239': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108240': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108241': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108242': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108243': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108244': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108245': 'colorectal carcinoma tissues',\n",
        "    'GSM3108246': 'colorectal carcinoma tissues',\n",
        "    'GSM3108247': 'colorectal carcinoma tissues',\n",
        "    'GSM3108248': 'colorectal carcinoma tissues',\n",
        "    'GSM3108249': 'colorectal carcinoma tissues',\n",
        "    'GSM3108250': 'colorectal carcinoma tissues',\n",
        "    'GSM3108251': 'colorectal carcinoma tissues',\n",
        "    'GSM3108252': 'colorectal carcinoma tissues',\n",
        "    'GSM3108253': 'colorectal carcinoma tissues',\n",
        "    'GSM3108254': 'colorectal carcinoma tissues',\n",
        "    'GSM3108255': 'colorectal carcinoma tissues',\n",
        "    'GSM3108256': 'colorectal carcinoma tissues',\n",
        "    'GSM3108257': 'colorectal carcinoma tissues',\n",
        "    'GSM3108258': 'colorectal carcinoma tissues'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK9FxmBMOZqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will be using the features dataset we defined earlier\n",
        "# This dataframe contains the 25 top and 25 bottom ranked genes\n",
        "df_features.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "076CmfX5wNzU",
        "colab_type": "text"
      },
      "source": [
        "## Data Formatting\n",
        "\n",
        "When using Scikit-Learn, each row should represent a set of observations for a sample.\n",
        "\n",
        "Currently the samples are represented using the columns, to fix this we can transpose the dataframe.\n",
        "\n",
        "The new dataframe will have a sample per row, and each column will represent a gene"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2aDo8W5Obkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scikit learn needs each row to represent a sample\n",
        "# for this reason we need to transpose the dataframe\n",
        "df_features = df_features.transpose()\n",
        "df_features.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra9q2qAiwuUM",
        "colab_type": "text"
      },
      "source": [
        "Now we should add an extra column that specifies the type of each sample. We will call this column label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W717ZvZOgPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add an extra column to the dataframe containing the sample label\n",
        "df_features['label'] = pd.Series(SAMPLES).astype('category')\n",
        "df_features.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21SoN7lKOg4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the category codes to label the samples types using integers\n",
        "df_features['label_codes'] = df_features[\"label\"].cat.codes\n",
        "df_features[[\"label\", 'label_codes']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk0QzDq9ygOD",
        "colab_type": "text"
      },
      "source": [
        "We will first subset the samples into a train test set to see how the model works.\n",
        "\n",
        "We will then use leave one out cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPMNBNBc2qSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_features.drop(columns=['label', 'label_codes']), \n",
        "    df_features['label_codes'], \n",
        "    test_size=0.92, \n",
        "    random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLJsYArsOzql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new logistic regression model\n",
        "# There are many different solvers: \n",
        "# .  https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "#   They all have their strenghts/weaknesses\n",
        "lr = LogisticRegression(random_state=0, solver='lbfgs')\n",
        "# train the model using the training data\n",
        "clf = lr.fit(X_train, y_train)\n",
        "# now that the model has been trained, predict the classes in the test set\n",
        "pred = clf.predict(X_test)\n",
        "# predict outputs labels, decision_function outputs the confidence scores\n",
        "y_scores = clf.decision_function(X_test)\n",
        "# print the accuracy sum(predicted == actual) / len(labels)\n",
        "print('Predicted Class:\\t', pred)\n",
        "print('Actual Class: \\t\\t', y_test.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2El42CY4O3ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y_scores contains the confidence scores\n",
        "y_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BN8chHhO5Dp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scoring the model will return the accuracy\n",
        "# this uses the test features and test labels\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtT3AQUF915S",
        "colab_type": "text"
      },
      "source": [
        "## Confusion Matrix\n",
        "\n",
        "A confusion matrix is good method for seeing how well your model made its classifications.\n",
        "\n",
        "If all the numbers fall along the diagonal it means that all the predictions were correct. If the numbers fall in any of the other blocks it means that they were misclassified"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26pgfrDu0bZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "disp = plot_confusion_matrix(clf, X_test, y_test,\n",
        "                                 display_labels=df_features['label'].cat.categories,\n",
        "                                 cmap=plt.cm.Blues,\n",
        "                                 normalize=None)\n",
        "disp.ax_.set_title('Confusion Matrix')\n",
        "disp.ax_.grid(False)\n",
        "disp.ax_.tick_params(axis='x', rotation=70)\n",
        "\n",
        "_ = disp.confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfubchll-VfB",
        "colab_type": "text"
      },
      "source": [
        "## Cross Validation\n",
        "\n",
        "The LeaveOneOut function will create training and testing sets.\n",
        "\n",
        "If we have 28 samples, there will be 28 of these sets. Each set will hold out one sample for testing and use the rest to train the model.\n",
        "\n",
        "When we iterate over the split it will return the indexes for the training and test sets.\n",
        "\n",
        "We can then use those indexes to subset the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGMvXimkVzAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for train_index, test_index in loo.split(df_features):\n",
        "  print(train_index, test_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxcW8J9SPKE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Leave one out cross validation using scikit\n",
        "\n",
        "# Create a new LeaveOneOut object and assign it to loo\n",
        "loo = LeaveOneOut()\n",
        "# Calculate the number of splits, this uses the number of rows in the features set\n",
        "loo.get_n_splits(df_features)\n",
        "\n",
        "max_probs = []\n",
        "\n",
        "# loo.split(features) will return column indexes for train and test sets\n",
        "# . the train will have len(samples) -1 elements\n",
        "# . the test set will contain a single index\n",
        "for train_index, test_index in loo.split(df_features):\n",
        "    # split the data into train and test sets using the indicies\n",
        "    df_features, \n",
        "    df_features\n",
        "    X_train = df_features.iloc[train_index].drop(columns=['label', 'label_codes'])\n",
        "    X_test = df_features.iloc[test_index].drop(columns=['label', 'label_codes'])\n",
        "    y_train = df_features.iloc[train_index]['label_codes']\n",
        "    y_test = df_features.iloc[test_index]['label_codes']\n",
        "    \n",
        "    # Create a new model each time so that the weights are reset each iteration \n",
        "    lr = LogisticRegression(solver='lbfgs')\n",
        "    # train the model using the training set\n",
        "    clf = lr.fit(X_train, y_train)\n",
        "    # print the accuracy of the model using the test set\n",
        "    print(clf.score(X_test, y_test), end=', ')\n",
        "    # this will output the probilites per test case\n",
        "    #   as we only have one test we can use zero to index it\n",
        "    max_probs.append(max(clf.predict_proba(X_test)[0]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH53ZnHf_GJD",
        "colab_type": "text"
      },
      "source": [
        "Using the probabilities we saved in the previous step we can recreate the predictive strength plot from the paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9x00VJy7GLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(2, 4), dpi=150)\n",
        "g = sns.stripplot(max_probs, orient='v')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MeiSrfxPT18",
        "colab_type": "text"
      },
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTyZK-vo_RJV",
        "colab_type": "text"
      },
      "source": [
        "## Imports\n",
        "\n",
        "- numpy\n",
        "- os\n",
        "- pandas\n",
        "- sklearn cluster\n",
        "  - KMean\n",
        "  - AgglomerativeClustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O04g_KnvPWee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y1RyheD_-ge",
        "colab_type": "text"
      },
      "source": [
        "## Loading the Data\n",
        "\n",
        "We will load the data again in case their were any changes in the previous sections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeP4_hgmP9GL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We use the raw data again as clustering should determine the groups\n",
        "#  If we used the feature set it would bias clusters towards the defined classes\n",
        "\n",
        "RAW_DATA_DIR = './data/raw/'\n",
        "RAW_DATA_FILENAME = 'GSE113513_series_matrix.txt.gz'\n",
        "\n",
        "samples = {\n",
        "    'GSM3108231': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108232': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108233': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108234': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108235': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108236': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108237': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108238': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108239': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108240': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108241': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108242': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108243': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108244': 'non-cancerous colorectal tissue',\n",
        "    'GSM3108245': 'colorectal carcinoma tissues',\n",
        "    'GSM3108246': 'colorectal carcinoma tissues',\n",
        "    'GSM3108247': 'colorectal carcinoma tissues',\n",
        "    'GSM3108248': 'colorectal carcinoma tissues',\n",
        "    'GSM3108249': 'colorectal carcinoma tissues',\n",
        "    'GSM3108250': 'colorectal carcinoma tissues',\n",
        "    'GSM3108251': 'colorectal carcinoma tissues',\n",
        "    'GSM3108252': 'colorectal carcinoma tissues',\n",
        "    'GSM3108253': 'colorectal carcinoma tissues',\n",
        "    'GSM3108254': 'colorectal carcinoma tissues',\n",
        "    'GSM3108255': 'colorectal carcinoma tissues',\n",
        "    'GSM3108256': 'colorectal carcinoma tissues',\n",
        "    'GSM3108257': 'colorectal carcinoma tissues',\n",
        "    'GSM3108258': 'colorectal carcinoma tissues'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EqSXV_sP_dZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the data into a dataframe\n",
        "df = pd.read_csv(\n",
        "    '{}{}'.format(RAW_DATA_DIR, RAW_DATA_FILENAME)\n",
        "    , comment='!',\n",
        "    sep='\\t',\n",
        "    \n",
        ")\n",
        "df = df.set_index('ID_REF')\n",
        "df_log = df.apply(np.log)\n",
        "df_log.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKJ35jPAAFM5",
        "colab_type": "text"
      },
      "source": [
        "## Data Formatting\n",
        "\n",
        "Once again, we will need to transpose the dataframe so that rows represent samples and columns represent genes.\n",
        "\n",
        "We will add the labels for each sample as a new column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQRTICJIQCRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scikit learn requires samples to be rows in the matrix\n",
        "#  For this reason we transpose the dataframe\n",
        "df_log = df_log.transpose()\n",
        "# We then add the labels to each row\n",
        "df_log['type'] = pd.Series(samples).astype('category')\n",
        "df_log['type_codes'] = df_log[\"type\"].cat.codes\n",
        "df_log.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoYierbXAWhx",
        "colab_type": "text"
      },
      "source": [
        "To simplify things we can split the dataframe into two. A features set containing the expression values, and a label set containing the labels for each sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9M09R-ZQEBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract the expression levels as features from the dataframe\n",
        "features = df_log.drop(columns=['type', 'type_codes']).values\n",
        "labels = df_log['type_codes'].values\n",
        "print('features:', features.shape)\n",
        "print('labels:', labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVebeYs7Ag7I",
        "colab_type": "text"
      },
      "source": [
        "## Clustering Methods\n",
        "\n",
        "We will use two different clustering methods. KMeans and Agglomerative (hierarchical) clustering. This demonstrates how easy it is to try out different models once your data is formatted correctly.\n",
        "\n",
        "Both of these methods require you to specify the number of clusters to make. They also have multiple parameters that can be set to fine tune the result.\n",
        "\n",
        "- https://scikit-learn.org/stable/modules/clustering.html#k-means\n",
        "- https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk_l7FWGQG18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a new clustering model and fit the features to it\n",
        "# K means requires the number of clusters to be specified\n",
        "kmeans = KMeans(n_clusters=4, random_state=123454321).fit(features)\n",
        "print('Clustering Labels:\\t', kmeans.labels_)\n",
        "print('Actual Labels:\\t\\t', labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh38EyUjAbuE",
        "colab_type": "text"
      },
      "source": [
        "From the results we can see that the cancerous tissue (code 0) all clustered together (cluster 1) while the non-cancerous (code 1) tissues was clustered into three groups (clusters 0, 2, 3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr4fI-l1QIrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The same process but with a different clustering model\n",
        "clustering = AgglomerativeClustering(n_clusters=4).fit(features)\n",
        "print('Clustering Labels:\\t', clustering.labels_)\n",
        "print('Actual Labels:\\t\\t', labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwOcGve2A7Fx",
        "colab_type": "text"
      },
      "source": [
        "The Agglomerative clustering clustered the cancerous and non-cancerous samples together. But it created two sub-classes for each. code 1 -> (clusters 0, 2) and code 0 -> (custers 1, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHOl1ueJBO9Q",
        "colab_type": "text"
      },
      "source": [
        "To understand the sub clusters we would need more information about source of the samples. Loading in extra data from the Meta Data of the file might allow us to understand why there are the sub clusters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8apnlRb9Q_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}